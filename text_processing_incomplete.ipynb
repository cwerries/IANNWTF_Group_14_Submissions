{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_processing_incomplete.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1FFpKVZlmW_xPzpoPKRPcOAdYi12IlIDk",
      "authorship_tag": "ABX9TyOnyI5dimwel3TRJCnKEUiO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cwerries/IANNWTF_Group_14_Submissions/blob/master/text_processing_incomplete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "17X-cWvKWMHE"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-text\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "import string\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.sequence import skipgrams \n",
        "from keras.preprocessing import text\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive._mount('/content/drive')\n",
        "os.chdir('drive/MyDrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wb-nHrJqWYSH",
        "outputId": "100a9f9c-1653-4c27-e97a-ee149d29b2e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "YrrVjxdPWfpk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get most_common_words"
      ],
      "metadata": {
        "id": "A6lunh-AWyv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def most_common_words(sentences): \n",
        "  tokenized = list(sum(sentences, []))\n",
        "  count = {}\n",
        "  for w in tokenized:\n",
        "    count[w] = count.get(w, 0) + 1  # create dictionary of words with counts\n",
        "\n",
        "  sorted_counts = dict(sorted(count.items(), key=lambda item: item[1], reverse=True))  #sort dictionary counts\n",
        "\n",
        "  keys = [key for key in sorted_counts.keys()][:10000]   #get 10000 most common words\n",
        "\n",
        "  return keys"
      ],
      "metadata": {
        "id": "haJkMVEqWfVM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keep only processed sentence parts"
      ],
      "metadata": {
        "id": "YWfF3_QJP3j6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "stop_words = nltk.corpus.stopwords.words('english') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aGGW5aVDVBJ",
        "outputId": "1f6fbe60-3ab3-406c-9c9d-92dccecb015b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('bible.txt') as f:\n",
        "    file = f.readlines()\n",
        "\n",
        "file = file[:5000]\n",
        "\n",
        "sentences = []\n",
        "for sentence in file:\n",
        "  if sentence != \"\\n\":\n",
        "    sentence = sentence.translate(str.maketrans('', '', string.digits))\n",
        "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "    sentences.append(sentence.lower().split())\n",
        "\n",
        "print(\"sentences: \", sentences[:2])\n",
        "\n",
        "sentences = [[token for token in s if token not in stop_words] for s in sentences]\n",
        "print(\"sentences: \", sentences[:2])\n",
        "\n",
        "keys = most_common_words(sentences)\n",
        "print(\"keys: \", keys[:5])\n",
        "\n",
        "# sentences with only most common tokens\n",
        "norm_bible = [[token for token in s if token in keys] for s in sentences]\n",
        "print(\"norm_bible: \", norm_bible[:2])\n",
        "\n",
        "norm_bible = [' '.join(tok_sent) for tok_sent in sentences]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sW7smAVWpKI",
        "outputId": "af1959d1-934e-443b-b180-92524e75147d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentences:  [['the', 'first', 'book', 'of', 'moses', 'called', 'genesis'], ['in', 'the', 'beginning', 'god', 'created', 'the', 'heaven', 'and', 'the', 'earth']]\n",
            "sentences:  [['first', 'book', 'moses', 'called', 'genesis'], ['beginning', 'god', 'created', 'heaven', 'earth']]\n",
            "keys:  ['unto', 'said', 'thou', 'thy', 'thee']\n",
            "norm_bible:  [['first', 'book', 'moses', 'called', 'genesis'], ['beginning', 'god', 'created', 'heaven', 'earth']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assigning numeric identifiers to words -> create vocabulary of words with indices"
      ],
      "metadata": {
        "id": "qGM7OCxoYVib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = text.Tokenizer()\n",
        "tokenizer.fit_on_texts(norm_bible)\n",
        "vocab = tokenizer.word_index\n",
        "inverse_vocab = {id:word for word, id in vocab.items()} #first index then word\n",
        "\n",
        "vocab_size = len(vocab) + 1 # padding included\n",
        "word_ids = [[vocab[id] for id in text.text_to_word_sequence(sent)] for sent in norm_bible]\n",
        "\n",
        "print('Vocabulary Size: ', vocab_size)\n",
        "print('Vocabulary Sample: ', list(vocab.items())[:5]) \n",
        "print(\"Sentences with word_ids: \", word_ids[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJY3aX2LYVL9",
        "outputId": "4e0b4e6d-4f98-4ef2-f05b-445259cfb3a6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size:  2441\n",
            "Vocabulary Sample:  [('unto', 1), ('said', 2), ('thou', 3), ('thy', 4), ('thee', 5)]\n",
            "Sentences with word_ids:  [[186, 814, 172, 25, 1413], [583, 7, 300, 122, 19]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate skip-grams\n",
        "skip_grams = [skipgrams(w_id, vocabulary_size=vocab_size, window_size=4, negative_samples = 0.0) for w_id in word_ids]\n",
        "\n",
        "# view sample skip-grams\n",
        "pairs, labels = skip_grams[0][0], skip_grams[0][1]\n",
        "\n",
        "for i in range(5):\n",
        "    print(\"({:s} ({:d}), {:s} ({:d}))\".format(\n",
        "          inverse_vocab[pairs[i][0]], pairs[i][0], \n",
        "          inverse_vocab[pairs[i][1]], pairs[i][1])) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz3P7V5TY-is",
        "outputId": "5b03cab7-b1fe-4a9f-ba21-9622096a23ff"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(genesis (1413), book (814))\n",
            "(first (186), genesis (1413))\n",
            "(genesis (1413), first (186))\n",
            "(called (25), book (814))\n",
            "(moses (172), book (814))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of Skipgrams with word ids"
      ],
      "metadata": {
        "id": "5ha0dL5ta4wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keep only word ids\n",
        "list_pairs = []\n",
        "for pair, _ in skip_grams:\n",
        "  list_pairs.append(pair)\n",
        "\n",
        "#flatten list\n",
        "flat_list = []\n",
        "for sublist in list_pairs:\n",
        "  for item in sublist:\n",
        "    if item[0] != item[1]:\n",
        "      flat_list.append(item)\n",
        "\n",
        "word_pairs_array = np.array(flat_list)\n",
        "#print(word_pairs_array[:200])\n",
        "# x = 0\n",
        "# for pair in word_pairs_array:\n",
        "#   if x <= 500:\n",
        "#     print(inverse_vocab[pair[0]], inverse_vocab[pair[1]])\n",
        "#     x += 1\n",
        "    "
      ],
      "metadata": {
        "id": "mRAfRubPajuD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create tensor dataset"
      ],
      "metadata": {
        "id": "0s-QqFy4kBrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_pairs_tensor =tf.data.Dataset.from_tensor_slices((word_pairs_array[:,0], word_pairs_array[:,1])) # create our data_set with inputs and targets\n",
        "word_pairs_tensor = word_pairs_tensor.map(lambda word,embed: (word,tf.reshape(embed,(-1,)))) # the labels must have shape (batchsize,1) or the nce won't work later\n",
        "prepared_ds = word_pairs_tensor.shuffle(1000).batch(32).prefetch(32)"
      ],
      "metadata": {
        "id": "xV32zOr_fyda"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "wrnJj6sGZgF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipGram(layers.Layer):\n",
        "    def __init__(self, vocab_size, embedding_size):\n",
        "        super(SkipGram, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "        self.build(\"x\")\n",
        "\n",
        "    def build(self, input_shape):\n",
        "      \n",
        "      # self.weight_matrix = tf.Variable(tf.random.normal([self.vocab_size, self.embedding_size])) # we wnat the nce_weights to be randomly distributed at the start\n",
        "      # self.score_bias = tf.Variable(tf.zeros([self.vocab_size])) # and the biases to be 0\n",
        "      # self.emb_matrix = tf.Variable(tf.random.uniform([self.vocab_size, self.embedding_size])) # we choose a uniform random variable for the embedding matrix\n",
        "\n",
        "      self.emb_matrix = self.add_weight(shape=(self.vocab_size, self.embedding_size), initializer='GlorotNormal')\n",
        "      self.weight_matrix = self.add_weight(shape=(self.vocab_size, self.embedding_size), initializer='GlorotNormal')\n",
        "      self.score_bias = self.add_weight(shape=(self.vocab_size), initializer='zeros')\n",
        "\n",
        "    def call(self, input, labels):\n",
        "        embeddings = tf.nn.embedding_lookup(self.emb_matrix, input)\n",
        "        nce_loss = tf.nn.nce_loss(\n",
        "            weights = self.weight_matrix,\n",
        "            biases = self.score_bias,\n",
        "            labels = labels,\n",
        "            inputs = embeddings,\n",
        "            num_sampled = 15,\n",
        "            num_classes = self.vocab_size\n",
        "            )\n",
        "        loss = tf.reduce_mean(nce_loss)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "FDEfCBekZ7sM"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "O75zOF-SbG1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_neighbours(model, check_words):\n",
        "  embeddings = model.emb_matrix.numpy()\n",
        "\n",
        "  for word in check_words:\n",
        "    word_id = vocab[word] # word ids of check_words\n",
        "\n",
        "    cosine_sim = []\n",
        "    #get closest word\n",
        "    for i in range(len(embeddings)):\n",
        "      cosine_sim.append(np.dot(embeddings[word_id], embeddings[i])/(norm(embeddings[word_id])*norm(embeddings[i])))\n",
        "\n",
        "    nearest_neighbours = np.argsort(cosine_sim)[:1]\n",
        "    print(\"To '\", word,\"' the nearest neighbour is: \", \",\".join([inverse_vocab[n] for n in nearest_neighbours]))"
      ],
      "metadata": {
        "id": "vyLdjTuOoZ2S"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# define hyperparams\n",
        "learning_rate = 0.01\n",
        "num_epochs = 10\n",
        "embedding_size = 64\n",
        "k = 5\n",
        "\n",
        "model = SkipGram(vocab_size, embedding_size)\n",
        "optimizer = tf.optimizers.Adam(learning_rate)\n",
        "#check_words= [\"holy\", \"father\", \"wine\", \"poison\", \"love\", \"strong\", \"day\" ]\n",
        "check_words = [\"moses\", \"book\", \"genesis\", \"earth\", \"heaven\", \"god\", \"spirit\"]\n",
        "losses = []\n",
        "\n",
        "# We train for num_epochs epochs.\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    epoch_loss_agg = []\n",
        "    for input,target in prepared_ds:\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "        loss = model(input, target) # get the loss\n",
        "      gradients = tape.gradient(loss, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "      epoch_loss_agg.append(loss)\n",
        "                   \n",
        "    losses.append(tf.reduce_mean(epoch_loss_agg))\n",
        "    \n",
        "    print(f'Epoch: {str(epoch)} with loss {losses[-1]}')\n",
        "\n",
        "    # after each epoch k nearest words\n",
        "    nearest_neighbours(model, check_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cguPm-zSbF27",
        "outputId": "5d2a75d1-24fe-4ccf-b6aa-7a8bc2ab4a4b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 with loss 15.112110137939453\n",
            "To ' moses ' the nearest neighbour is:  carmi\n",
            "To ' book ' the nearest neighbour is:  ashamed\n",
            "To ' genesis ' the nearest neighbour is:  ashamed\n",
            "To ' earth ' the nearest neighbour is:  ashamed\n",
            "To ' heaven ' the nearest neighbour is:  ashamed\n",
            "To ' god ' the nearest neighbour is:  renown\n",
            "To ' spirit ' the nearest neighbour is:  renown\n",
            "Epoch: 1 with loss 5.048102378845215\n",
            "To ' moses ' the nearest neighbour is:  doer\n",
            "To ' book ' the nearest neighbour is:  ashamed\n",
            "To ' genesis ' the nearest neighbour is:  ashamed\n",
            "To ' earth ' the nearest neighbour is:  ashamed\n",
            "To ' heaven ' the nearest neighbour is:  ashamed\n",
            "To ' god ' the nearest neighbour is:  doer\n",
            "To ' spirit ' the nearest neighbour is:  ashamed\n",
            "Epoch: 2 with loss 4.555867671966553\n",
            "To ' moses ' the nearest neighbour is:  renown\n",
            "To ' book ' the nearest neighbour is:  ashamed\n",
            "To ' genesis ' the nearest neighbour is:  ashamed\n",
            "To ' earth ' the nearest neighbour is:  bethlehem\n",
            "To ' heaven ' the nearest neighbour is:  ashamed\n",
            "To ' god ' the nearest neighbour is:  doer\n",
            "To ' spirit ' the nearest neighbour is:  ashamed\n",
            "Epoch: 3 with loss 4.060805797576904\n",
            "To ' moses ' the nearest neighbour is:  renown\n",
            "To ' book ' the nearest neighbour is:  ashamed\n",
            "To ' genesis ' the nearest neighbour is:  ashamed\n",
            "To ' earth ' the nearest neighbour is:  bethlehem\n",
            "To ' heaven ' the nearest neighbour is:  ashamed\n",
            "To ' god ' the nearest neighbour is:  doer\n",
            "To ' spirit ' the nearest neighbour is:  ashamed\n",
            "Epoch: 4 with loss 3.710498094558716\n",
            "To ' moses ' the nearest neighbour is:  calneh\n",
            "To ' book ' the nearest neighbour is:  ashamed\n",
            "To ' genesis ' the nearest neighbour is:  ashamed\n",
            "To ' earth ' the nearest neighbour is:  tithes\n",
            "To ' heaven ' the nearest neighbour is:  ashamed\n",
            "To ' god ' the nearest neighbour is:  doer\n",
            "To ' spirit ' the nearest neighbour is:  ashamed\n",
            "Epoch: 5 with loss 3.4546053409576416\n",
            "To ' moses ' the nearest neighbour is:  raamses\n",
            "To ' book ' the nearest neighbour is:  ashamed\n",
            "To ' genesis ' the nearest neighbour is:  ashamed\n",
            "To ' earth ' the nearest neighbour is:  tithes\n",
            "To ' heaven ' the nearest neighbour is:  ashamed\n",
            "To ' god ' the nearest neighbour is:  doer\n",
            "To ' spirit ' the nearest neighbour is:  carmi\n",
            "Epoch: 6 with loss 3.2789244651794434\n",
            "To ' moses ' the nearest neighbour is:  raamses\n",
            "To ' book ' the nearest neighbour is:  ashamed\n",
            "To ' genesis ' the nearest neighbour is:  ashamed\n",
            "To ' earth ' the nearest neighbour is:  tithes\n",
            "To ' heaven ' the nearest neighbour is:  ashamed\n",
            "To ' god ' the nearest neighbour is:  doer\n",
            "To ' spirit ' the nearest neighbour is:  carmi\n",
            "Epoch: 7 with loss 3.195237398147583\n",
            "To ' moses ' the nearest neighbour is:  raamses\n",
            "To ' book ' the nearest neighbour is:  ashamed\n",
            "To ' genesis ' the nearest neighbour is:  ashamed\n",
            "To ' earth ' the nearest neighbour is:  tithes\n",
            "To ' heaven ' the nearest neighbour is:  ashamed\n",
            "To ' god ' the nearest neighbour is:  doer\n",
            "To ' spirit ' the nearest neighbour is:  ashamed\n",
            "Epoch: 8 with loss 3.1564834117889404\n",
            "To ' moses ' the nearest neighbour is:  raamses\n",
            "To ' book ' the nearest neighbour is:  ashamed\n",
            "To ' genesis ' the nearest neighbour is:  ashamed\n",
            "To ' earth ' the nearest neighbour is:  tithes\n",
            "To ' heaven ' the nearest neighbour is:  ashamed\n",
            "To ' god ' the nearest neighbour is:  doer\n",
            "To ' spirit ' the nearest neighbour is:  carmi\n",
            "Epoch: 9 with loss 3.0899884700775146\n",
            "To ' moses ' the nearest neighbour is:  overspread\n",
            "To ' book ' the nearest neighbour is:  raamses\n",
            "To ' genesis ' the nearest neighbour is:  ashamed\n",
            "To ' earth ' the nearest neighbour is:  tithes\n",
            "To ' heaven ' the nearest neighbour is:  ashamed\n",
            "To ' god ' the nearest neighbour is:  doer\n",
            "To ' spirit ' the nearest neighbour is:  carmi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot losses"
      ],
      "metadata": {
        "id": "OnrMPR-j9xox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(losses)\n",
        "plt.title(\"Train losses\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "V4ZOVuu19tFS",
        "outputId": "4b1fb8bd-2214-40e5-bd26-e0533cf20231"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}