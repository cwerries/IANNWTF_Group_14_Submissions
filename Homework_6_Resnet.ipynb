{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework 6 - Resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cwerries/IANNWTF_Group_14_Submissions/blob/master/Homework_6_Resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvCdiVCYqI3X"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1QlsECVX5LW"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwdjcFXjqKyP"
      },
      "source": [
        "Loading dataset Cifar-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAecSFt1YC6j",
        "outputId": "d857eff3-3b77-4186-b86e-2e4630ad0245"
      },
      "source": [
        "(training_inputs, training_labels), (test_inputs, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "print(\"Training inputs: \" + str(training_inputs.shape))\n",
        "print(\"Training labels: \" + str(training_labels.shape))\n",
        "print(\"Test inputs: \" + str(test_inputs.shape))\n",
        "print(\"Test labels: \" + str(test_labels.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training inputs: (50000, 32, 32, 3)\n",
            "Training labels: (50000, 1)\n",
            "Test inputs: (10000, 32, 32, 3)\n",
            "Test labels: (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa6OACT22bgx"
      },
      "source": [
        "Input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBozHjQoYGPK"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Creates tensorflow datasets for the training and test data.\n",
        "training_dataset = tf.data.Dataset.from_tensor_slices((training_inputs, training_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_inputs, test_labels))\n",
        "\n",
        "# Conducts the normalization of the inputs (images) and the one-hot-encoding of the targets.\n",
        "training_dataset = training_dataset.map(lambda inp, tar: (inp, tf.one_hot(tf.squeeze(tar), 10)))\n",
        "# tf.squeeze(tar) to remove dimensions of size 1 from the shape of the target-tensors.\n",
        "training_dataset = training_dataset.map(lambda inp, tar: ((2*(inp/255)-1), tar))\n",
        "\n",
        "# Conducts the normalization of the inputs (images) and the one-hot-encoding of the targets.\n",
        "test_dataset = test_dataset.map(lambda inp, tar: (inp, tf.one_hot(tf.squeeze(tar), 10)))\n",
        "# tf.squeeze(tar) to remove dimensions of size 1 from the shape of the target-tensors.\n",
        "test_dataset = test_dataset.map(lambda inp, tar: ((2*(inp/255)-1), tar))\n",
        "                                                                                          \n",
        "# Batches, shuffles and prefetches the training- and test datasets.\n",
        "training_dataset = training_dataset.batch(batch_size)\n",
        "training_dataset = training_dataset.shuffle(batch_size*10)\n",
        "training_dataset = training_dataset.prefetch(batch_size*2)\n",
        "\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "test_dataset = test_dataset.shuffle(batch_size*10)\n",
        "test_dataset = test_dataset.prefetch(batch_size*2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYL1QBJrYIiK"
      },
      "source": [
        "# Description: The class ResidualBlock describes a residual block of a ResNet.\n",
        "#              With residual blocks, inputs can forward propagate faster through the residual connections across layers.\n",
        "class ResidualBlock(tf.keras.layers.Layer): \n",
        "  \n",
        "  def __init__(self):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "\n",
        "    self.conv_1 = tf.keras.layers.Conv2D(filters = 120,\n",
        "                                         kernel_size = 1,activation = None, \n",
        "                                         padding = 'same', \n",
        "                                         kernel_initializer = tf.keras.initializers.glorot_normal,   \n",
        "                                         bias_initializer = 'zeros', \n",
        "                                         kernel_regularizer = tf.keras.regularizers.L2(0.01))        \n",
        "    \n",
        "    self.batch_norm_1 = tf.keras.layers.BatchNormalization()                                        \n",
        "    \n",
        "    self.activ_1 = tf.keras.activations.relu                          \n",
        "    \n",
        "    self.conv_2 = tf.keras.layers.Conv2D(filters = 120,\n",
        "                                         kernel_size = 3,\n",
        "                                         activation = None,\n",
        "                                         padding = 'same',\n",
        "                                         kernel_initializer = tf.keras.initializers.glorot_normal,   \n",
        "                                         bias_initializer = 'zeros',                                 \n",
        "                                         kernel_regularizer = tf.keras.regularizers.L2(0.01))       \n",
        "    \n",
        "    self.batch_norm_2 = tf.keras.layers.BatchNormalization()                                        \n",
        "    \n",
        "    self.activ_2 = tf.keras.activations.relu\n",
        "    \n",
        "    self.dropout_2 = tf.keras.layers.Dropout(rate = 0.5)                                            \n",
        "    \n",
        "    self.conv_3 = tf.keras.layers.Conv2D(filters = 120,\n",
        "                                         kernel_size = 1,\n",
        "                                         activation = None,\n",
        "                                         padding = 'same',\n",
        "                                         kernel_initializer = tf.keras.initializers.glorot_normal,   \n",
        "                                         bias_initializer = 'zeros',                                \n",
        "                                         kernel_regularizer = tf.keras.regularizers.L2(0.01))       \n",
        "    \n",
        "    self.batch_norm_3 = tf.keras.layers.BatchNormalization()                                        \n",
        "    \n",
        "    self.activ_3 = tf.keras.activations.relu\n",
        "\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, block_input, training = True):\n",
        "    x = self.conv_1(block_input)\n",
        "    x = self.batch_norm_1(x, training)\n",
        "    x = self.activ_1(x)\n",
        "    x = self.conv_2(x)\n",
        "    x = self.batch_norm_2(x, training)\n",
        "    x = self.activ_2(x)\n",
        "    x = self.dropout_2(x, training)\n",
        "    x = self.conv_3(x)\n",
        "    x = self.batch_norm_3(x, training)\n",
        "    x = self.activ_3(x)\n",
        "\n",
        "    block_output = block_input + x\n",
        "    return block_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLD9ZwaoYIkR"
      },
      "source": [
        "# Description: The class ResNet describes a residual convolutional neural network with a feature extractor and a classifier.\n",
        "#              Consists of residual blocks. Introduces “identity shortcut connection”.\n",
        "class ResNet(tf.keras.Model): \n",
        "  \n",
        "  def __init__(self, num_residual_blocks):\n",
        "    super(ResNet, self).__init__()\n",
        "\n",
        "    # Feature extractor\n",
        "    self.conv_1 = tf.keras.layers.Conv2D(filters = 120,\n",
        "                                         kernel_size = 3,\n",
        "                                         activation = None,\n",
        "                                         padding = 'same',\n",
        "                                         kernel_initializer = tf.keras.initializers.glorot_normal,  \n",
        "                                         bias_initializer = 'zeros',                               \n",
        "                                         kernel_regularizer = tf.keras.regularizers.L2(0.01),      \n",
        "                                         input_shape = (32, 32, 3))\n",
        "    \n",
        "    self.batch_norm_1 = tf.keras.layers.BatchNormalization()                                     \n",
        "    \n",
        "    self.activ_1 = tf.keras.activations.relu    \n",
        "    \n",
        "    self.dropout_1 = tf.keras.layers.Dropout(rate = 0.4)                                           \n",
        "\n",
        "    # create residual blocks.\n",
        "    self.residual_blocks = []\n",
        "    for _ in range(num_residual_blocks):\n",
        "      self.residual_blocks.append(ResidualBlock())\n",
        "\n",
        "    # Classifier\n",
        "    self.global_pool = tf.keras.layers.GlobalAveragePooling2D()   #pool_size = 3, strides = 2, padding = 'same'\n",
        "    self.dropout = tf.keras.layers.Dropout(rate = 0.4)                                              \n",
        "    self.output_layer = tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, x, training = True):\n",
        "    x = self.conv_1(x)\n",
        "    x = self.batch_norm_1(x, training)\n",
        "    x = self.activ_1(x)\n",
        "    x = self.dropout_1(x, training)\n",
        "\n",
        "    for res_block in self.residual_blocks:\n",
        "      x = res_block(x, training)\n",
        "\n",
        "    x = self.global_pool(x)\n",
        "    x = self.dropout(x, training)\n",
        "    x = self.output_layer(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJT3XmtcYInD"
      },
      "source": [
        "#@tf.function\n",
        "def training_step(model, training_data, loss_fn, optimizer, training = True):\n",
        "  training_losses = []\n",
        "  training_accuracies = []\n",
        "\n",
        "  for (input, target) in training_data:\n",
        "    with tf.GradientTape() as tape:\n",
        "      prediction = model(input, training)\n",
        "      current_training_loss = loss_fn(target, prediction)+ tf.math.reduce_sum(model.losses)   \n",
        "      gradients = tape.gradient(current_training_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    training_losses.append(current_training_loss.numpy())\n",
        "\n",
        "    current_training_accuracy = np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\n",
        "    training_accuracies.append(np.mean(current_training_accuracy))  \n",
        "  \n",
        "  training_loss = np.mean(training_losses)\n",
        "  training_accuracy = np.mean(training_accuracies)\n",
        "  return training_loss, training_accuracy\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def test(model, test_data, loss_fn, training = False):\n",
        "  test_losses = []\n",
        "  test_accuracies = []\n",
        "\n",
        "  for (input, target) in test_data:\n",
        "    prediction = model(input, training)\n",
        "    \n",
        "    current_test_loss = loss_fn(target, prediction)\n",
        "    test_losses.append(current_test_loss.numpy())\n",
        "\n",
        "    current_test_accuracy = np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\n",
        "    test_accuracies.append(np.mean(current_test_accuracy))   \n",
        "    \n",
        "  test_loss = np.mean(test_losses)\n",
        "  test_accuracy = np.mean(test_accuracies)\n",
        "  return test_loss, test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhi_nwPpYJPS",
        "outputId": "7320f0b8-8fab-4e67-d676-ed0db5ad5509"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "num_residual_blocks = 6\n",
        "model = ResNet(num_residual_blocks) \n",
        "\n",
        "n_epochs = 10\n",
        "learning_rate = 0.0001\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()                    \n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, amsgrad = True)    \n",
        "\n",
        "training_losses = []\n",
        "training_accuracies = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "# Training and test loop\n",
        "for epoch in range(n_epochs):\n",
        "    print('Epoch ' + str(epoch))\n",
        "\n",
        "    training_loss, training_accuracy = training_step(model, training_dataset, loss_fn, optimizer, training = True)\n",
        "    training_losses.append(training_loss)\n",
        "    training_accuracies.append(training_accuracy)\n",
        "\n",
        "    test_loss, test_accuracy = test(model, test_dataset, loss_fn, training = False)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    print(\"Training accuracy: \" + str(training_accuracy))\n",
        "    print(\"Test accuracy: \" + str(test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "Training accuracy: 0.18446291560102301\n",
            "Test accuracy: 0.2177547770700637\n",
            "Epoch 1\n",
            "Training accuracy: 0.2805306905370844\n",
            "Test accuracy: 0.37798566878980894\n",
            "Epoch 2\n",
            "Training accuracy: 0.3651094948849105\n",
            "Test accuracy: 0.43869426751592355\n",
            "Epoch 3\n",
            "Training accuracy: 0.4212156329923274\n",
            "Test accuracy: 0.484375\n",
            "Epoch 4\n",
            "Training accuracy: 0.4547434462915601\n",
            "Test accuracy: 0.5218949044585988\n",
            "Epoch 5\n",
            "Training accuracy: 0.4827365728900256\n",
            "Test accuracy: 0.4635748407643312\n",
            "Epoch 6\n",
            "Training accuracy: 0.5111492966751918\n",
            "Test accuracy: 0.48835589171974525\n",
            "Epoch 7\n",
            "Training accuracy: 0.5277533567774936\n",
            "Test accuracy: 0.4856687898089172\n",
            "Epoch 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1nWR5Q3YJTh"
      },
      "source": [
        "plt.figure()\n",
        "line1, = plt.plot(training_losses)\n",
        "line2, = plt.plot(test_losses)\n",
        "plt.xlabel(\"Training steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend((line1, line2),(\"Test\", \"Training\"))\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "line1, = plt.plot(training_accuracies)\n",
        "line2, = plt.plot(test_accuracies)\n",
        "plt.xlabel(\"Training steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend((line1, line2),(\"Test\", \"Training\"))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}