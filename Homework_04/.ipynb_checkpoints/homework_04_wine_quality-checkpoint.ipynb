{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fedf8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#print(tf.test.gpu_device_name())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fe2c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank wine into good or bad\n",
    "# function receiving a target and returning a binary value depending if target >= predefined threshold\n",
    "def make_binary(target, threshold):\n",
    "    if target >= tf.constant(threshold, dtype=tf.int32):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aef1a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.hidden_layer1 = tf.keras.layers.Dense(32, activation=tf.nn.relu, kernel_regularizer= regularizers.l2(0.001))\n",
    "        self.hidden_layer2 = tf.keras.layers.Dense(32, activation=tf.nn.relu, kernel_regularizer= regularizers.l2(0.001))\n",
    "        self.dropout = tf.keras.layers.Dropout(0.1)\n",
    "        self.output_layer = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training = False):\n",
    "        x = self.hidden_layer1(inputs)\n",
    "        x = self.hidden_layer2(x)\n",
    "        if training:\n",
    "            x = self.dropout(x, training=training)    \n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b84984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, input, target, loss_function, optimizer):\n",
    "    # loss_object and optimizer_object are instances of respective tensorflow classes\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = model(input)\n",
    "        loss = loss_function(target, prediction)\n",
    "        sample_train_accuracy =  target == np.round(prediction)\n",
    "        sample_train_accuracy = np.mean(sample_train_accuracy)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss, sample_train_accuracy\n",
    "\n",
    "def validate(model, val_data, loss_function):\n",
    "    # test over complete test data\n",
    "\n",
    "    val_accuracy_aggregator = []\n",
    "    val_loss_aggregator = []\n",
    "\n",
    "    for (input, target) in val_data:\n",
    "        prediction = model(input)\n",
    "        sample_val_loss = loss_function(target, prediction)\n",
    "        sample_val_accuracy =  target == np.round(prediction)\n",
    "        sample_val_accuracy = np.mean(sample_val_accuracy)\n",
    "        val_loss_aggregator.append(sample_val_loss.numpy())\n",
    "        val_accuracy_aggregator.append(np.mean(sample_val_accuracy))\n",
    "\n",
    "    val_loss = tf.reduce_mean(val_loss_aggregator)\n",
    "    val_accuracy = tf.reduce_mean(val_accuracy_aggregator)\n",
    "\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "\n",
    "def test(model, test_data, loss_function):\n",
    "    # test over complete test data\n",
    "\n",
    "    test_accuracy_aggregator = []\n",
    "    test_loss_aggregator = []\n",
    "\n",
    "    for (input, target) in test_data:\n",
    "        prediction = model(input)\n",
    "        sample_test_loss = loss_function(target, prediction)\n",
    "        sample_test_accuracy =  target == np.round(prediction)\n",
    "        sample_test_accuracy = np.mean(sample_test_accuracy)\n",
    "        test_loss_aggregator.append(sample_test_loss.numpy())\n",
    "        test_accuracy_aggregator.append(np.mean(sample_test_accuracy))\n",
    "\n",
    "    test_loss = tf.reduce_mean(test_loss_aggregator)\n",
    "    test_accuracy = tf.reduce_mean(test_accuracy_aggregator)\n",
    "\n",
    "    return test_loss, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "654a66a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize accuracy and loss for training and test data.\n",
    "def plotting(train_losses, test_losses, val_losses, train_accuracies, test_accuracies, val_accuracies):\n",
    "    # plot losses\n",
    "    plt.figure()\n",
    "    line1, = plt.plot(train_losses)\n",
    "    line2, = plt.plot(test_losses)\n",
    "    line3, = plt.plot(val_losses)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Training steps\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend((line1,line2,line3),(\"Loss train\",\"Loss test\",\"Loss validate\"))\n",
    "    plt.show()\n",
    "    \n",
    "    # plot accuracies\n",
    "    plt.figure()\n",
    "    line1, = plt.plot(train_accuracies)\n",
    "    line2, = plt.plot(test_accuracies)\n",
    "    line3, = plt.plot(val_accuracies)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.xlabel(\"Training steps\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend((line1,line2,line3),(\"Accuracy train\", \"Accuracy test\",\"Accuracy validate\"))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c13259c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset, threshold):\n",
    "    # ranking wine in good and bad depending on threshold -> binary calssification\n",
    "    # Data Pipeline \n",
    "    \n",
    "    # map make_binary() function to dataset\n",
    "    dataset = dataset.map(lambda inputs, target: (inputs, make_binary(target, threshold)))\n",
    "  \n",
    "    # shuffle\n",
    "    dataset = dataset.shuffle(1599)\n",
    "    \n",
    "    # apply batching \n",
    "    dataset = dataset.batch(128)\n",
    "\n",
    "    # prefetch data\n",
    "    dataset = dataset.prefetch(128)\n",
    "\n",
    "    #return preprocessed dataset\n",
    "    return dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e88979",
   "metadata": {},
   "source": [
    "## Preparation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddabaf92",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5200/926520077.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m train_ds = (\n\u001b[0;32m     20\u001b[0m     tf.data.Dataset.from_tensor_slices(\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     )\n\u001b[0;32m     23\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[1;34m(x, dtype, name)\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m       \u001b[1;31m# strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m   \"\"\"\n\u001b[1;32m--> 263\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    264\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    273\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m   \u001b[1;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_tfrt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m           \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_ContextOptionsSetTfrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_tfrt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 539\u001b[1;33m         \u001b[0mcontext_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_NewContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    540\u001b[0m       \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_DeleteContextOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load data into a data frame\n",
    "df_wine = pd.read_csv('winequality-red.csv', sep = \";\", index_col = False)\n",
    "# shuffle dataframe\n",
    "df_wine = df_wine.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# define features and target labels\n",
    "features = list(df_wine.columns)[:-1]\n",
    "target = \"quality\"\n",
    "\n",
    "# calculate threshold of all qualities using median\n",
    "#threshold = df_wine[target].median()\n",
    "threshold = 7\n",
    "\n",
    "# Create a Tensorflow Dataset and a Dataset Pipeline\n",
    "## split data frame into train(60%), test(20%), validation(20%)\n",
    "train_df, test_df, val_df = np.split(df_wine.sample(frac=1, random_state=42), [int(0.6*len(df_wine)), int(0.8*len(df_wine))])\n",
    "\n",
    "## convert dataframes into tensorflow datasets\n",
    "train_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.cast(train_df[features].values, tf.float32), tf.cast(train_df[target].values, tf.int32))\n",
    "    )\n",
    ")\n",
    "\n",
    "test_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.cast(test_df[features].values, tf.float32), tf.cast(test_df[target].values, tf.int32))\n",
    "    )\n",
    ")\n",
    "\n",
    "val_ds = ( tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.cast(val_df[features].values, tf.float32), tf.cast(val_df[target].values, tf.int32))\n",
    "    )\n",
    ")\n",
    "\n",
    "# prepare datasets\n",
    "train_dataset = prepare_dataset(train_ds, threshold)\n",
    "\n",
    "test_dataset = prepare_dataset(test_ds, threshold)\n",
    "val_dataset = prepare_dataset(val_ds, threshold)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea5b278",
   "metadata": {},
   "source": [
    "## Training and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb6bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.0002\n",
    "    \n",
    "# Initialize the optimizers: SGD, Adam, RMSprop\n",
    "optimizers = [tf.keras.optimizers.SGD(learning_rate), tf.keras.optimizers.RMSprop(learning_rate) , tf.keras.optimizers.Adam(learning_rate) ]\n",
    "opt_labels = [\"SGD\", \"RMSprop\" , \"Adam\"]\n",
    "label = 0\n",
    "\n",
    "for opt in optimizers:\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # Initialize the model.\n",
    "    model = MyModel()\n",
    "    # Initialize the loss: categorical cross entropy. Check out 'tf.keras.losses'.\n",
    "    b_cross_entropy_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "\n",
    "    # Initialize lists for later visualization.\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    \n",
    "    #testing once before we begin\n",
    "    test_loss, test_accuracy = test(model, test_dataset, b_cross_entropy_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    #check how model performs on train data once before we begin\n",
    "    train_loss, train_accuracy = test(model, train_dataset, b_cross_entropy_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    #check how model performs on validate data once before we begin\n",
    "    val_loss, val_accuracy = test(model, val_dataset, b_cross_entropy_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    \n",
    "    # We train for num_epochs epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        #training (and checking in with training)\n",
    "        epoch_loss_agg = []\n",
    "        epoch_acc_agg = []\n",
    "        for input,target in train_dataset:\n",
    "            train_loss, train_accuracy = train_step(model, input, target, b_cross_entropy_loss, opt)\n",
    "            epoch_loss_agg.append(train_loss)\n",
    "\n",
    "            #track training loss\n",
    "        train_losses.append(tf.reduce_mean(epoch_loss_agg))\n",
    "        # tracking train accuracy\n",
    "        train_accuracies.append(tf.reduce_mean(train_accuracy))\n",
    "        \n",
    "        #testing, so we can track accuracy and test loss\n",
    "        test_loss, test_accuracy = test(model, test_dataset, b_cross_entropy_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        # validation\n",
    "        val_loss, val_accuracy = validate(model, val_dataset, b_cross_entropy_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        #print(f' test_losses: {test_losses[-1]} , test_accuracies: {test_accuracies[-1]}')\n",
    "        #print(f' val_losses: {val_losses[-1]}, test_accuracies: {test_accuracies[-1]}')\n",
    "        \n",
    "    print(opt_labels[label], \"optimizer\")\n",
    "    label+=1\n",
    "\n",
    "    plotting(train_losses, test_losses, val_losses, train_accuracies, test_accuracies, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3856e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ff3eae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
